{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Navigation Project - Image Processing and Computer Vision - a.y. 2024/25\n",
    "\n",
    "**Professor**: Luigi Di Stefano\n",
    "\n",
    "**Student**: Andrea Perna - Automation Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1) Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "This project focuses on developing an obstacle detection system for autonomous navigation using stereo vision. Given synchronized video sequences from a stereo camera mounted on a moving vehicle, the system estimates the distance to the obstacle (i.e., the chessboard) by computing disparity maps through two methods: the dense Semi-Global Block Matching (SGBM) algorithm and a sparse keypoint-based approach leveraging the chessboard's corners. The latter method, applied to chessboard patterns in the scene, enhances stability by reducing noise and fluctuations in distance estimation compared to dense disparity mapping. The project includes real-time distance monitoring, chessboard dimension estimation, and safety alerts when the vehicle approaches the critical distance, providing reliable input for collision avoidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Dataset\n",
    "\n",
    "The dataset comprises synchronized stereo videos captured in a cluttered scenario. A centrally placed chessboard pattern is a key reference for computing disparity maps and obstacle distances.\n",
    "\n",
    "<img src=\"Project_Images/left_dataset_view.png\" alt=\"Dataset\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/right_dataset_view.png\" alt=\"Dataset\" style=\"width:30%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2) Settings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#suppress warnings\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"Keypoints\"  #stereo matching method: \"SGBM\" for dense matching or \"Keypoints\" for sparse, chessboard-based matching.\n",
    "robust_mean = True  #if True, the median is used instead of the mean for estimating the main disparity, improving robustness to noise.\n",
    "corners_refinement = True #if True, it allows refinement of extracted corners ofthe chessboard\n",
    "enable_plots = True #if True, it enables metrics visualization and saving\n",
    "generate_maps = True #if True, enables disparity and depth map creation and storage\n",
    "threshold = False #if True, it plots the width and height' plots with visible thresholds\n",
    "stereo_block_size = 15  #size of the block used to compare pixel intensities between left and right images in StereoSGBM algorithm.\n",
    "central_window_radius = 10  #used to crop the disparity map to focus on a smaller region in the center of the frame for efficient noise reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_height = 0  #initial vertical crop of the disparity region, allowing adjustments for focusing on central areas.\n",
    "crop_width = 0  #initial horizontal crop of the disparity region, ensuring that computations focus on the region of interest.\n",
    "disparity_SGBM = 0 #initialization of the disparity value between the two images\n",
    "first_frame = True #boolean flag indicating the first frame for computing the initial disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "output_directory = os.path.join(base_dir, \"Project_Outcomes\")\n",
    "left_video_path = os.path.join(base_dir, \"robot-navigation-video\", \"robotL.avi\")\n",
    "right_video_path = os.path.join(base_dir, \"robot-navigation-video\", \"robotR.avi\")\n",
    "output_video_path = os.path.join(output_directory, \"output_video_final.avi\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera and Chessboard Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera parameters\n",
    "f = 567.2  #focal length in pixels\n",
    "b = 92.226  #baseline distance between stereo cameras in mm\n",
    "\n",
    "#chessboard parameters\n",
    "chessboard_grid = (8, 6)  #chessboard grid size\n",
    "real_width = 125  #real chessboard width (mm)\n",
    "real_height = 178  #real chessboard height (mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FONT = cv2.FONT_HERSHEY_DUPLEX #font type\n",
    "FONT_SCALE = 0.6 #general font scale\n",
    "ALERT_FONT_SCALE = 0.8 #font scale of alert message\n",
    "TEXT_COLOR = (255, 255, 255)  #white text\n",
    "SAFE_COLOR = (0, 255, 0)  #green for safe navigation\n",
    "RED_ALERT_COLOR = (0, 0, 255)  #red for warnings\n",
    "SHADOW_COLOR = (0, 0, 0)  #shadow for contrast\n",
    "THICKNESS = 1 #font tickness\n",
    "alarm_counter = 0  #counter for triggering warnings\n",
    "min_dist = 800  #minimum safe distance in mm\n",
    "\n",
    "#font alternatives\n",
    "cv2.FONT_HERSHEY_SIMPLEX   #a basic sans-serif font, commonly used for general-purpose text due to good readability.\n",
    "cv2.FONT_HERSHEY_COMPLEX   #a serif-style font with more detail, suitable for formal or stylized text.\n",
    "cv2.FONT_HERSHEY_TRIPLEX   #a A bold serif-style font, ideal for emphasis and headings.\n",
    "cv2.FONT_HERSHEY_PLAIN     #a minimalist font with very thin, simple text, good for compact or subtle labeling.\n",
    "cv2.FONT_HERSHEY_DUPLEX    #a thicker version of the basic sans-serif font, providing better visibility while maintaining readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Storage and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = { #data structure to store key metrics\n",
    "    \n",
    "    #distances    \n",
    "    \"distances_keypoints\": [],\n",
    "    \"distances_SGBM\": [],\n",
    "\n",
    "    #chessboard dimensions\n",
    "    \"widths_keypoints\": [],\n",
    "    \"heights_keypoints\": [],\n",
    "    \"widths_SGBM\": [],\n",
    "    \"heights_SGBM\": [],\n",
    "\n",
    "    #angles estimations\n",
    "    \"angles_keypoints\": [],\n",
    "    \"angles_SGBM\": [],\n",
    "    \n",
    "    #disparity\n",
    "    \"disparity_maps\": [],\n",
    "    \"depth_maps\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3) Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initialization Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function initializes the video processing pipeline, it opens the left and right synchronized video files, checks for loading issues, and retrieves key properties like frame dimensions and frame rate. It also initializes an output video writer to save the processed frames as an AVI file, which will contain the algorithm's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_initialization(left_video_path, right_video_path, output_video_path):\n",
    "\n",
    "    #open the left and right video streams\n",
    "    left_video = cv2.VideoCapture(left_video_path)\n",
    "    right_video = cv2.VideoCapture(right_video_path)\n",
    "\n",
    "    #check if videos were successfully opened\n",
    "    if not (left_video.isOpened() and right_video.isOpened()):\n",
    "        raise IOError(\"ERROR: Problem encountered during the opening of the videos.\")\n",
    "    else: print(\"Videos opened correctly.\\n\")\n",
    "\n",
    "    #retrieve video properties (assume both videos have the same properties)\n",
    "    frame_width = int(left_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(left_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_rate = left_video.get(cv2.CAP_PROP_FPS)\n",
    "    video_length = int(left_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    #initialize the output video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    output_video = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    print(f\"Video Properties: Frame_Width={frame_width}, Frame_Height={frame_height}, FPS={frame_rate}, Video_Length={video_length}\")\n",
    "\n",
    "    return left_video, right_video, output_video, frame_width, frame_height, frame_rate, video_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frame Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function reads and validates frames from the left and right video streams. Valid frames are converted to grayscale for stereo matching and keypoint detection. If frames are missing or corrupted, they are skipped to maintain smooth and uninterrupted execution of the video processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_preprocessing(left_video, right_video, frame_number):\n",
    "    \n",
    "    #read frames from both videos\n",
    "    rL, frameL = left_video.read()\n",
    "    rR, frameR = right_video.read()\n",
    "\n",
    "    #check if frames are missing or corrupted\n",
    "    if not rL or not rR or frameL is None or frameR is None:\n",
    "        print(f\"\\nSkipping frame {frame_number}: Unable to read video frames.\")\n",
    "        return None  #indicate that frames should be skipped\n",
    "\n",
    "    #convert frames to grayscale\n",
    "    frameL_gray = cv2.cvtColor(frameL, cv2.COLOR_BGR2GRAY)\n",
    "    frameR_gray = cv2.cvtColor(frameR, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return frameL, frameR, frameL_gray, frameR_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualization Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function saves the disparity map of a given video frame as an image for visualization. The map is normalized to range [0, 255] to enhance visibility and saved in the specified output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/disp_map1.png\" alt=\"Save Map\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/disp_map2.png\" alt=\"Save Map\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/depth_map.png\" alt=\"Save Map\" style=\"width:30%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_map(map_data, map_type, frame_number, output_directory):\n",
    "\n",
    "    #normalize the map to [0, 255] for proper visualization\n",
    "    normalized_map = cv2.normalize(map_data, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "    normalized_map = np.uint8(normalized_map)\n",
    "\n",
    "    #create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    #generate the file name\n",
    "    file_name = os.path.join(output_directory, f\"{map_type}_map_frame{frame_number}.png\")\n",
    "\n",
    "    #save the image\n",
    "    cv2.imwrite(file_name, normalized_map)\n",
    "    print(f\"Saved {map_type} map as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function overlays estimated information on each video frame, such as obstacle distance, chessboard dimensions, angle estimates, and progress status. If the distance to the obstacle is below the safety threshold, a red visual alarm is triggered and managed by the alarm counter. Chessboard corners are shown when detected, and the processed frame is written to the output video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/display_info_safe_SGBM.png\" alt=\"Visualization\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/display_info_alarm_SGBM.png\" alt=\"Visualization\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/display_info_safe_k.png\" alt=\"Visualization\" style=\"width:30%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_information(frame, alarm_counter, distance_keypoint, min_dist, chessboard_width, chessboard_height, angle_tau, chessboard_grid, corners, found, frame_number, video_length, output_video):\n",
    "\n",
    "    #subfunction for drawing text with shadow\n",
    "    def draw_text(text, position, color=TEXT_COLOR, font_scale=FONT_SCALE, thickness=THICKNESS):\n",
    "        \n",
    "        \"\"\"\n",
    "        Draw text with a shadow to improve readability on any background.\n",
    "        \"\"\"\n",
    "        shadow_offset = (position[0] + 2, position[1] + 2)  # Slight offset for shadow effect\n",
    "        cv2.putText(frame, text, shadow_offset, FONT, font_scale, SHADOW_COLOR, thickness + 1, cv2.LINE_AA)  # Shadow\n",
    "        cv2.putText(frame, text, position, FONT, font_scale, color, thickness, cv2.LINE_AA)  # Main text\n",
    "\n",
    "    #trigger visual alarm if distance is below the threshold\n",
    "    if distance_keypoint < min_dist:\n",
    "\n",
    "        frame[:, :, 1] //= [4, 2, 3][((alarm_counter // 2) % 6) % 3]  #reduce green\n",
    "        frame[:, :, 0] //= [4, 2, 3][((alarm_counter // 2) % 6) % 3]  #reduce blue\n",
    "        alarm_counter += 1  #update alarm counter\n",
    "\n",
    "        #warning message in bold red\n",
    "        draw_text(f\"ALERT - OBSTACLE AHEAD: {np.around(distance_keypoint / 1000, 3)} m\", (20, 40), RED_ALERT_COLOR, ALERT_FONT_SCALE, 2)\n",
    "    \n",
    "    #safe navigation message in bold green\n",
    "    else: draw_text(f\"SAFE ROBOT NAVIGATION: {np.around(distance_keypoint / 1000, 3)} m\", (20, 40), SAFE_COLOR, ALERT_FONT_SCALE, 2)\n",
    "\n",
    "    #header for estimated information\n",
    "    draw_text(f\"ESTIMATED INFORMATION ({method})\", (20, 110))\n",
    "\n",
    "    #display chessboard and angle information\n",
    "    info_texts = [\n",
    "        f\"-Minimum Safety Distance: {np.around(min_dist/1000, 3)} m\",\n",
    "        f\"-Chess width: {np.around(chessboard_width, 3)} mm\",\n",
    "        f\"-Chess height: {np.around(chessboard_height, 3)} mm\",\n",
    "        f\"-Angle: {np.around(angle_tau, 3)} DEG\",\n",
    "    ]\n",
    "\n",
    "    #draw all information lines with consistent spacing\n",
    "    for i, text in enumerate(info_texts): draw_text(text, (20, 140 + i * 30))\n",
    "\n",
    "    #display progress information\n",
    "    progress_text = f\"Progress: {(frame_number / video_length) * 100:.1f}% | Frame {frame_number + 1}/{video_length}\"\n",
    "    draw_text(progress_text, (20, frame.shape[0] - 20), font_scale=FONT_SCALE)\n",
    "\n",
    "    #draw chessboard corners if detected\n",
    "    if found: cv2.drawChessboardCorners(frame, chessboard_grid, corners, found)\n",
    "\n",
    "    #write frame to output video\n",
    "    output_video.write(frame)\n",
    "\n",
    "    return alarm_counter  #return updated alarm counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function analyzes and compares the performance of the keypoint and SGBM methods by plotting distance, width, and height measurements across frames. It also computes the relative percentage differences between the two methods and highlights keyframes for disparity map visualization. The plots and some representative disparity maps are saved in the output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/angles_plot.png\" alt=\"Metrics\" style=\"width:33%;\"/>\n",
    "<img src=\"Project_Images/distance_comparison_MEDIAN.png\" alt=\"Metrics\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/distance_comparison_MEAN.png\" alt=\"Metrics\" style=\"width:30%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(metrics_data, output_directory, min_dist):\n",
    "\n",
    "    ########################################\n",
    "    ######### Data Preprocessing ###########\n",
    "    ########################################\n",
    "    \n",
    "    #convert distances into NumPy arrays\n",
    "    distances_keypoints = np.array(metrics_data[\"distances_keypoints\"])[1:] / 1000  #skip first frame\n",
    "    distances_SGBM = np.array(metrics_data[\"distances_SGBM\"])[1:] / 1000  #skip first frame\n",
    "    min_dist_m = min_dist / 1000  #convert min_dist to meters\n",
    "\n",
    "    #convert widths, heights and angles to NumPy arrays\n",
    "    widths_keypoints = np.array(metrics_data[\"widths_keypoints\"])[1:]\n",
    "    widths_keypoints, heights_keypoints = np.array(metrics_data[\"widths_keypoints\"][1:]), np.array(metrics_data[\"heights_keypoints\"][1:])\n",
    "    widths_SGBM, heights_SGBM = np.array(metrics_data[\"widths_SGBM\"][1:]), np.array(metrics_data[\"heights_SGBM\"][1:])\n",
    "    angles_keypoints = np.array(metrics_data[\"angles_keypoints\"][1:])\n",
    "    #angles_SGBM = np.array(metrics_data[\"angles_SGBM\"])[1:]\n",
    "\n",
    "    #compute relative percentage differences for distances\n",
    "    relative_distance_difference = (np.abs(distances_SGBM - distances_keypoints) / distances_keypoints) * 100\n",
    "    avg_relative_distance_diff = np.mean(relative_distance_difference)\n",
    "\n",
    "    ########################################\n",
    "    ######## Depth & Disparity Maps ########\n",
    "    ########################################\n",
    "    \n",
    "    #identify representative frames (25%, 50%, 75%)\n",
    "    total_frames = len(distances_keypoints)\n",
    "    representative_frames = [total_frames // 4, total_frames // 2, 3 * total_frames // 4]\n",
    "\n",
    "    if generate_maps:\n",
    "        \n",
    "        for frame_num in representative_frames:\n",
    "\n",
    "            #extract the full maps\n",
    "            full_disparity_map = metrics_data[\"disparity_maps\"][frame_num]\n",
    "            full_depth_map = metrics_data[\"depth_maps\"][frame_num]\n",
    "\n",
    "            #to save maps with overlayed text\n",
    "            save_map(full_disparity_map, \"Disparity Map\", frame_num + 1, output_directory)\n",
    "            save_map(full_depth_map, \"Depth Map\", frame_num + 1, output_directory)\n",
    "        \n",
    "    ########################################\n",
    "    ############ Metrics Plots #############\n",
    "    ########################################\n",
    "\n",
    "    if enable_plots:\n",
    "\n",
    "        # -------- Plot 1: Distance Comparison --------\n",
    "        frames = np.arange(1, len(distances_keypoints) + 1)  #start from frame 1\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(frames, distances_keypoints, label='Keypoints Distance', color='blue', linewidth=2)\n",
    "        plt.plot(frames, distances_SGBM, label='SGBM Distance', color='red', linestyle='dashed', linewidth=2)\n",
    "        plt.axhline(y=min_dist_m, color='green', linestyle='dotted', linewidth=2, label=f'Min Safe Distance ({min_dist_m:.2f} m)')\n",
    "        plt.xlabel(\"Frame Number\")\n",
    "        plt.ylabel(\"Distance (m)\")\n",
    "        if robust_mean: plt.title(\"Distance Comparison Across Frames [MEDIAN DISPARITY]\")\n",
    "        else: plt.title(\"Distance Comparison Across Frames [MEAN DISPARITY]\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        output_file = f\"{output_directory}/distance_comparison.png\"\n",
    "        plt.savefig(output_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Distance comparison plot saved to {output_file}\")\n",
    "\n",
    "        # -------- Plot 2: Chessboard Width Comparison --------\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(frames, widths_keypoints, label='Keypoints Width', color='blue', linewidth=2)\n",
    "        plt.plot(frames, widths_SGBM, label='SGBM Width', color='red', linestyle='dashed', linewidth=2)\n",
    "        if threshold: plt.axhline(y=real_width, color='green', linestyle='dotted', linewidth=2, label=f'Real Width ({real_width:.2f} mm)')\n",
    "        plt.xlabel(\"Frame Number\")\n",
    "        plt.ylabel(\"Width (mm)\")\n",
    "        plt.title(\"Chessboard Width Comparison\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        output_file = f\"{output_directory}/width_comparison.png\"\n",
    "        plt.savefig(output_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Chessboard width comparison plot saved to {output_file}\")\n",
    "\n",
    "        # -------- Plot 3: Chessboard Height Comparison --------\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(frames, heights_keypoints, label='Keypoints Height', color='blue', linewidth=2)\n",
    "        plt.plot(frames, heights_SGBM, label='SGBM Height', color='red', linestyle='dashed', linewidth=2)\n",
    "        if threshold: plt.axhline(y=real_height, color='green', linestyle='dotted', linewidth=2, label=f'Real Height ({real_height:.2f} mm)')\n",
    "        plt.xlabel(\"Frame Number\")\n",
    "        plt.ylabel(\"Height (mm)\")\n",
    "        plt.title(\"Chessboard Height Comparison\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        output_file = f\"{output_directory}/height_comparison.png\"\n",
    "        plt.savefig(output_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Chessboard height comparison plot saved to {output_file}\")\n",
    "\n",
    "        # -------- Plot 4: Relative Distance Difference --------\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(frames, relative_distance_difference, label='Relative Distance Difference (%)', color='purple', linewidth=2)\n",
    "        plt.xlabel(\"Frame Number\")\n",
    "        plt.ylabel(\"Relative Difference (%)\")\n",
    "        plt.title(f\"Relative Distance Difference (Avg: {avg_relative_distance_diff:.2f}%)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        output_file = f\"{output_directory}/relative_distance_difference.png\"\n",
    "        plt.savefig(output_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Relative distance difference plot saved to {output_file}\")\n",
    "\n",
    "        # -------- Plot 5: Relative Distance Difference (Semi-log scale) --------\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.semilogy(frames, relative_distance_difference, label='Relative Distance Difference (%)', color='purple', linewidth=2)\n",
    "        plt.xlabel(\"Frame Number\")\n",
    "        plt.ylabel(\"Relative Difference (%)\")\n",
    "        plt.title(f\"Relative Distance Difference (Avg: {avg_relative_distance_diff:.2f}%)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, which=\"both\", linestyle='--')  #grid for both major and minor ticks\n",
    "        output_file = f\"{output_directory}/relative_distance_difference_log.png\"\n",
    "        plt.savefig(output_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Relative distance difference plot (log scale) saved to {output_file}\")\n",
    "\n",
    "        # -------- Plot 6: Angle Plot (Keypoints) --------\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(frames, angles_keypoints, label=\"Chessboard Angles\", color='blue', linestyle='-')\n",
    "        #plt.plot(angles_SGBM, label=\"SGBM Angle\", color='red', linestyle='--')\n",
    "        plt.xlabel(\"Frame Number\")\n",
    "        plt.ylabel(\"Angle (degrees)\")\n",
    "        plt.title(\"Chessboard Angles Across Frames\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_directory, \"angles.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point Cloud (Sketchfab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/point_cloudA.png\" alt=\"PointCloud\" style=\"width:40%;\"/>\n",
    "<img src=\"Project_Images/point_cloudB.png\" alt=\"PointCloud\" style=\"width:47%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates a **3D point cloud** from a given disparity map and saves it as a PLY (Polygon File Format) file. The disparity map, computed from a stereo camera setup, provides depth information, which is then converted into 3D world coordinates using the known camera’s intrinsic parameters: focal length (f) and baseline distance (b). Key steps follow:\n",
    "\n",
    "1. **Depth Estimation:** The disparity map is used to compute the depth $Z = (f * b) / d$.\n",
    "2. **Point Projection:** Using known camera intrinsics, each pixel's (X, Y, Z) coordinates in 3D space are determined.\n",
    "3. **Color Association:** The color of each 3D point is taken from the corresponding pixel in the left camera frame.\n",
    "4. **PLY File Saving:** The computed 3D points along with their color information are written to a PLY file (visualized with Sketchfab).\n",
    "\n",
    "The function is indeed using the perspective projection equation, but working with its inverse transformation to go from 2D pixel coordinates $(u,v)$ back to 3D world coordinates $(X,Y,Z)$.\n",
    "$$X = \\frac{(u -c_x) \\cdot Z}{f}, \\quad Y = \\frac{(v-c_y) \\cdot Z}{f}, \\quad Z = \\frac{f \\cdot b}{d}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_point_cloud(disparity_map, frameL, f, b, output_filename=\"point_cloud.ply\"):\n",
    "\n",
    "    #ensure proper scaling\n",
    "    disparity_map = disparity_map.astype(np.float32) / 16.0\n",
    "\n",
    "    #apply a bilateral filter for smooth depth estimation\n",
    "    disparity_map = cv2.bilateralFilter(disparity_map, d=5, sigmaColor=50, sigmaSpace=50)\n",
    "\n",
    "    #mmage size\n",
    "    h, w = disparity_map.shape\n",
    "\n",
    "    #compute depth (Z) from disparity\n",
    "    valid_mask = disparity_map > 0.8  #ignore invalid disparities\n",
    "    Z = np.zeros_like(disparity_map, dtype=np.float32)\n",
    "    Z[valid_mask] = (f * b) / disparity_map[valid_mask]\n",
    "\n",
    "    #define the piercing point\n",
    "    cx = w/2\n",
    "    cy = h/2\n",
    "\n",
    "    #compute 3D coordinates\n",
    "    v, u = np.indices((h, w))\n",
    "    X = (u - cx) * Z / f\n",
    "    Y = (v - cy) * Z / f\n",
    "\n",
    "    #apply mask and reshape to valid points\n",
    "    points = np.column_stack((X[valid_mask], Y[valid_mask], Z[valid_mask]))\n",
    "    \n",
    "    #extract color information from the image\n",
    "    colors = cv2.cvtColor(frameL, cv2.COLOR_BGR2RGB)[valid_mask] if frameL is not None else np.zeros_like(points)\n",
    "\n",
    "    #save as PLY file\n",
    "    with open(output_filename, \"w\") as ply:\n",
    "        ply.write(f\"ply\\nformat ascii 1.0\\nelement vertex {len(points)}\\n\")\n",
    "        ply.write(\"property float x\\nproperty float y\\nproperty float z\\n\")\n",
    "        ply.write(\"property uchar red\\nproperty uchar green\\nproperty uchar blue\\nend_header\\n\")\n",
    "        for (x, y, z), (r, g, b) in zip(points, colors):\n",
    "            ply.write(f\"{x} {y} {z} {r} {g} {b}\\n\")\n",
    "\n",
    "    print(f\"Saved improved point cloud as {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Estimation Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine Chessboard Corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function refines the initial chessboard corner detections to improve the accuracy of subsequent disparity and distance calculations. Using OpenCV’s cornerSubPix method, the corner positions are iteratively adjusted to sub-pixel accuracy based on image gradients, enhancing accuracy. The function also ensures that the corners are ordered correctly by checking their spatial layout and flipping them if necessary. Proper ordering of corners ensures accurate correspondence between the left and right images, which is essential for reliable stereo matching and distance estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_chessboard_corners(frameL_gray, frameR_gray, cornersL, cornersR):\n",
    "\n",
    "    #define termination criteria\n",
    "    termination_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 1)\n",
    "\n",
    "    #refine corners using sub-pixel accuracy\n",
    "    cv2.cornerSubPix(frameL_gray, cornersL, (5, 5), (-1, -1), termination_criteria)\n",
    "    cv2.cornerSubPix(frameR_gray, cornersR, (5, 5), (-1, -1), termination_criteria)\n",
    "\n",
    "    #ensure correct order of corners, look at 1st and 8th corners\n",
    "    if cornersL[0][0][0] > cornersL[8][0][0]: cornersL = np.flip(cornersL, 0)\n",
    "    if cornersR[0][0][0] > cornersR[8][0][0]: cornersR = np.flip(cornersR, 0)\n",
    "\n",
    "    return cornersL, cornersR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/corners1.png\" alt=\"CornersRefinement\" style=\"width:21%;\"/>\n",
    "<img src=\"Project_Images/reversed_corners.png\" alt=\"CornersRefinement\" style=\"width:17%;\"/>\n",
    "<img src=\"Project_Images/corners3.png\" alt=\"CornersRefinement\" style=\"width:23%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance & Disparity Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **keypoint-based method**, disparity is computed as the difference in x-coordinates of corresponding chessboard corners: $d=u_L​−u_R$​. These values form a $(6×8)$ disparity matrix, averaged column-wise, then across columns for a robust final disparity. The chessboard’s distance is then estimated using the stereo vision formula:\n",
    "$\\text{z}_{\\text{k}} =  \\frac{f \\cdot b}{\\text{d}_\\text{mean}}$. This approach leverages stable keypoints, offering more reliable distance estimation than SGBM, especially in noisy conditions. The formulas used for the mean disparity computation are shown below:\n",
    "\n",
    "$$d_{\\text{columns}}(j) = \\frac{1}{8} \\sum_{i=1}^{8} \\left( u_L^{i,j} - u_R^{i,j} \\right) \\quad \\text{and} \\quad d_{\\text{keypoints}} = \\frac{1}{6} \\sum_{j=1}^{6} d_{\\text{columns}}(j)$$\n",
    "\n",
    "The **StereoSGBM** (Semi-Global Block Matching) algorithm computes a dense disparity map by matching pixels between rectified grayscale stereo frames within an adaptive disparity range. It minimizes the energy function $E(D)$, balancing local matching costs and global smoothness constraints across multiple scanline directions.\n",
    "To optimize computation, only a central region is processed, considering padding factors like block size, minimum disparity, and search range. A focused window is then extracted for distance estimation, reducing overhead. The disparity is refined using the median (for robustness) or mean, and converted into obstacle distance via the stereo vision depth formula. Optimal disparity is found as the solution of the following optimization problem:\n",
    "\n",
    "$$D(x, y) = \\arg\\min_d E(D) \\quad \\text{where} \\quad E(D) = \\sum_{(x,y)} C(x, y, D(x, y)) + \\sum_{(x,y)} P(D(x,y), D(x', y')) \\quad \\text{and} \\quad P(D(x,y), D(x',y')) = \\begin{cases}\n",
    "   0, & \\text{if } D(x,y) = D(x',y') \\\\\n",
    "   P_1, & \\text{if } |D(x,y) - D(x',y')| = 1 \\\\\n",
    "   P_2, & \\text{if } |D(x,y) - D(x',y')| > 1\n",
    "\\end{cases}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/disparity_theory.png\" alt=\"Distance&Disparity\" style=\"width:18%;\"/>\n",
    "<img src=\"Project_Images/relative_distance_difference.png\" alt=\"Distance&Disparity\" style=\"width:31%;\"/>\n",
    "<img src=\"Project_Images/relative_distance_difference_log.png\" alt=\"Distance&Disparity\" style=\"width:31%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_disparity_estimation(cornersL, cornersR, initial_disparity, frameL_gray, frameR_gray, frame_width, frame_height):\n",
    "\n",
    "    def extract_disparity_crop(full_disparity_map, frame_height, frame_width, central_window_radius, stereo_block_size, NumDisparities, offset):\n",
    "        \n",
    "        \"\"\"extracts a cropped region from the disparity map\"\"\"\n",
    "\n",
    "        #define cropping factors\n",
    "        half_h, half_w = frame_height // 2, frame_width // 2 #compute the center of the frame\n",
    "        stereo_adjustment = (stereo_block_size - 1) // 2 #adjust for block size to ensure proper alignment\n",
    "        disparity_adjustment = NumDisparities + offset #adjust width to accommodate the disparity search range\n",
    "\n",
    "        #compute the cropping indeces\n",
    "        h_start, h_end = half_h - central_window_radius - stereo_adjustment, half_h + central_window_radius + stereo_adjustment\n",
    "        w_start, w_end = half_w - central_window_radius - disparity_adjustment - stereo_adjustment, half_w + central_window_radius + stereo_adjustment\n",
    "\n",
    "        #return the cropped central region for disparity calculations\n",
    "        return full_disparity_map[h_start:h_end, w_start:w_end]\n",
    "\n",
    "    ########################################\n",
    "    ########## Keypoints Disparity #########\n",
    "    ########################################\n",
    "\n",
    "    #calculate disparity columns from chessboard corners (hor. coordinates)\n",
    "    disparity_matrix = cornersL[:, 0, 0].reshape(8, 6) - cornersR[:, 0, 0].reshape(8, 6)\n",
    "\n",
    "    #average over rows to get column disparities\n",
    "    disparity_columns = np.mean(disparity_matrix, axis=0).reshape(6, 1)\n",
    "\n",
    "    #compute the mean disparity across all columns\n",
    "    disparity_keypoints = np.mean(disparity_columns)\n",
    "\n",
    "    ########################################\n",
    "    ############ SGBM Disparity ############\n",
    "    ########################################\n",
    "\n",
    "    #adjust disparity search range\n",
    "    offset = max(0, int(initial_disparity - 32)) if initial_disparity >= 32 else 0\n",
    "    NumDisparities = min(max(64 + offset, 64), 128)  #minimum 64, cap at 128 for stability\n",
    "\n",
    "    #define the penalty term for SGBM\n",
    "    P1 = 2 * stereo_block_size**2\n",
    "    P2 = 12 * stereo_block_size**2\n",
    "    \n",
    "    #create StereoSGBM object\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = offset, numDisparities = NumDisparities, blockSize = stereo_block_size, P1 = P1, P2 = P2)\n",
    "\n",
    "    #compute dense disparity map\n",
    "    full_disparity_map = stereo.compute(frameL_gray, frameR_gray).astype(np.float32) / 16\n",
    "    \n",
    "    #crop the disparity map\n",
    "    cropped_disparity_map = extract_disparity_crop(full_disparity_map, frame_height, frame_width, central_window_radius, stereo_block_size, NumDisparities, offset)\n",
    "\n",
    "    #compute main disparity for distance estimation\n",
    "    if robust_mean: disparity_SGBM = np.median(cropped_disparity_map[cropped_disparity_map > 0])\n",
    "    else: disparity_SGBM = np.mean(cropped_disparity_map)\n",
    "\n",
    "    ########################################\n",
    "    ############ Depth Estimation ###########\n",
    "    ########################################\n",
    "\n",
    "    #estimate the depth with both methods\n",
    "    distance_keypoints, distance_SGBM = (f * b) / disparity_keypoints, (f * b) / disparity_SGBM\n",
    "\n",
    "    #compute the depth map\n",
    "    depth_map = np.where(full_disparity_map > 0, (f * b) / full_disparity_map, 0)\n",
    "\n",
    "    ########################################\n",
    "    ############### Results ################\n",
    "    ########################################\n",
    "\n",
    "    return {\n",
    "        \"distance_keypoints\": distance_keypoints,\n",
    "        \"disparity_keypoints\": disparity_keypoints,\n",
    "        \"disparity_columns\": disparity_columns,\n",
    "        \"distance_SGBM\": distance_SGBM,\n",
    "        \"disparity_SGBM\": disparity_SGBM,\n",
    "        \"disparity_map_full\": full_disparity_map,\n",
    "        \"disparity_map_crop\": cropped_disparity_map,\n",
    "        \"depth_map\": depth_map\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chessboard Size Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the real-world width and height of the chessboard pattern by processing corner points detected in both the left and right stereo images. For each view, it sums the distances between corresponding corner points along rows (for width) and columns (for height) and scales them using the known distance to the chessboard and the camera’s focal length. Finally, the averaged distances from both rows and columns are combined across views to provide robust estimates of the chessboard pattern’s dimensions in millimeters. Perspective Projection reads:\n",
    "$$W = \\frac{w \\cdot Z}{f} \\quad H = \\frac{h \\cdot Z}{f}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/width_comparison_blank.png\" alt=\"ChessboardSize\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/height_comparison_blank.png\" alt=\"ChessboardSize\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/chess_size.png\" alt=\"ChessboardSize\" style=\"width:16%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keypoint-based method demonstrates more stability, with fewer fluctuations, due to the reliability of chessboard corner detection. On the other hand, the SGBM-based method shows larger variability, especially in regions where the disparity map is less reliable (e.g., around frames 150–250). Indeed, after frame 250, accuracy worsens due to the robot’s rapid rotation and closer proximity, causing significant changes in the 3D-to-2D projection. Spikes in the SGBM graph may be due to noise in dense disparity calculations, which can be subject of future improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chessboard_size_estimation(corners_list, z, f):\n",
    "\n",
    "    #initialize results \n",
    "    total_width = 0\n",
    "    total_height = 0\n",
    "\n",
    "    #access number of rows and columns\n",
    "    n_rows = chessboard_grid[0]\n",
    "    n_columns = chessboard_grid[1]\n",
    "\n",
    "    #precompute scaling factor\n",
    "    scale_factor = z / f\n",
    "\n",
    "    #loop through both cornersL and cornersR\n",
    "    for corners in corners_list:\n",
    "\n",
    "        #ensure corners have the correct layout (6x8)\n",
    "        assert len(corners) >= 48, \"Insufficient chessboard corners detected. Expected at least 48.\"\n",
    "\n",
    "        #calculate the width of the chessboard by summing distances between corners in each row\n",
    "        width_sum = sum((abs(corners[i][0][0] - corners[40 + i][0][0]) * scale_factor) for i in range(n_rows))\n",
    "\n",
    "        #calculate the height of the chessboard by summing distances between corners in each column\n",
    "        height_sum = sum((abs(corners[8 * j][0][1] - corners[8 * j + 7][0][1]) * scale_factor) for j in range(n_columns))\n",
    "\n",
    "        #accumulate the averages along chessboard's dimensions\n",
    "        total_width += width_sum / n_rows  #average across the 8 rows\n",
    "        total_height += height_sum / n_columns #average across the 6 columns\n",
    "\n",
    "    #compute the final average width and height using both left and right views\n",
    "    chessboard_width = total_width / 2\n",
    "    chessboard_height = total_height / 2\n",
    "\n",
    "    return chessboard_width, chessboard_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chessboard Angle Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function estimates the angle *τ* between the obstacle (represented by a chessboard) and the camera’s image plane, which is essential for determining the obstacle’s orientation. The angle is calculated based on the disparity differences between the closest and farthest vertical stripes of the chessboard. Specifically, the function computes the difference in depth ΔZ as:\n",
    "$$ \\Delta Z = \\left| \\frac{f \\cdot b}{d_{\\text{min}}} - \\frac{f \\cdot b}{d_{\\text{max}}} \\right| $$\n",
    "where *dmin​* and *dmax*​ are the disparities of the closest and farthest stripes. The depth difference *ΔZ* is then combined with the chessboard width *w* to calculate the angle with arctangent function. This formula holds due to Perspective Projection, which projects the chessboard's width line onto the image plane; however, the higher the angle the worse will be the geometric assumption.  \n",
    "$$ \\tau = \\arctan\\left( \\frac{\\Delta Z}{w} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Project_Images/angle_estimation1.png\" alt=\"ChessAngle\" style=\"width:24%;\"/>\n",
    "<img src=\"Project_Images/angle_estimation2.png\" alt=\"ChessAngle\" style=\"width:30%;\"/>\n",
    "<img src=\"Project_Images/angles_plot.png\" alt=\"ChessAngle\" style=\"width:36%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The angle was computed using the keypoint-based disparity method, which leverages the disparities at detected chessboard corners. Sudden spikes in the graph may indicate frames where the keypoints were poorly detected or temporarily lost. Overall, the stable regions with small angles suggest that the chessboard was largely aligned with the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chessboard_angle_estimation(disparity_values, width_chess):\n",
    "\n",
    "    #compute depth differences using disparity values at the first and last columns\n",
    "    delta_depth = abs((f * b) / disparity_values[0] - (f * b) / disparity_values[5])\n",
    "\n",
    "    #compute the angle using arctangent\n",
    "    angle_tau = math.degrees(math.atan(delta_depth / width_chess))\n",
    "\n",
    "    return angle_tau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3) Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, the algorithm initializes and opens the left and right video streams by retrieving their properties (e.g., frame size, rate, and length), and preparing the output video for writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos opened correctly.\n",
      "\n",
      "Video Properties: Frame_Width=640, Frame_Height=480, FPS=15.0, Video_Length=389\n"
     ]
    }
   ],
   "source": [
    "left_video, right_video, output_video, frame_width, frame_height, frame_rate, video_length = video_initialization(left_video_path, right_video_path, output_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop iterates through each frame of the stereo video, performing sequential operations to estimate the desidered information from the dataset. The main tasks in the loop include:\n",
    "- **Frame Pre-Processing**: reads and converts the left and right frames of the given videos to grayscale for further analysis by using frame_preprocessing() function.\n",
    "- **Chessboard Corner Detection**: detects the chessboard corners in both frames using cv2.findChessboardCorners(), followed by sub-pixel refinement using refine_chessboard_corners().\n",
    "- **Disparity and Distance Estimation**: calculates disparity values by using both keypoint-based and dense SGBM methods, by returning depth and disparity information for further analyses.\n",
    "- **Chessboard Size Calculation**: computes the real-world width and height of the chessboard in millimeters by scaling corner distances using the focal length and current distance.\n",
    "- **Angle Estimation**: estimates the angle τ between the chessboard and the camera’s image plane using disparity differences across vertical stripes.\n",
    "- **Information Visualization**: displays obstacle information, such as distance, dimensions, and angle, within the video frames. Safety warnings are triggered if the obstacle is too close.\n",
    "- **Metrics Storage**: stores key data, including distances, widths, heights, and angles, for further analysis, evaluation and storage which will be taken at the end of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.8% | Frame 3/389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3553/3478726205.py:62: RuntimeWarning: divide by zero encountered in divide\n",
      "  depth_map = np.where(full_disparity_map > 0, (f * b) / full_disparity_map, 0)\n",
      "/tmp/ipykernel_3553/2854069748.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  angle_tau = math.degrees(math.atan(delta_depth / width_chess))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% | Frame 389/389"
     ]
    }
   ],
   "source": [
    "for frame_number in range(video_length):  #iterate through the frames of videos\n",
    "\n",
    "    #print progress as a percentage alongside the number of frames\n",
    "    print(f\"\\rProgress: {((frame_number+1) / video_length) * 100:.1f}% | Frame {frame_number + 1}/{video_length}\", end=\"\")\n",
    "\n",
    "    ###############################\n",
    "    ##### Frame Pre-Processing ####\n",
    "    ###############################\n",
    "\n",
    "    #read and pre-process current frames\n",
    "    result = frame_preprocessing(left_video, right_video, frame_number)\n",
    "    \n",
    "    #unpack current frames\n",
    "    if result is None: continue  \n",
    "    frameL, frameR, frameL_gray, frameR_gray = result\n",
    "\n",
    "    ###############################\n",
    "    ###### Corners Extraction #####\n",
    "    ###############################\n",
    "    \n",
    "    #detect chessboard corners\n",
    "    foundL, cornersL = cv2.findChessboardCorners(frameL_gray, chessboard_grid)\n",
    "    foundR, cornersR = cv2.findChessboardCorners(frameR_gray, chessboard_grid)\n",
    "    if not (foundL and foundR): continue #skip frame if corners are not found \n",
    "\n",
    "    #refine corners using sub-pixel accuracy\n",
    "    if corners_refinement: cornersL, cornersR = refine_chessboard_corners(frameL_gray, frameR_gray, cornersL, cornersR)\n",
    "\n",
    "    ###############################\n",
    "    ##### Distance & Disparity ####\n",
    "    ###############################\n",
    "\n",
    "    if first_frame: #use keypoints disparity to initialize SGBM search range on the first frame\n",
    "        \n",
    "        disparity_SGBM = np.mean(cornersL[:, 0, 0] - cornersR[:, 0, 0])  \n",
    "        first = False  #disable initialization for future frames\n",
    "\n",
    "    #estimate disparity and distance\n",
    "    results = distance_disparity_estimation(cornersL, cornersR, disparity_SGBM, frameL_gray, frameR_gray, frame_width, frame_height)\n",
    "    \n",
    "    #extract relevant values\n",
    "    distance_keypoints, disparity_keypoints, disparity_columns, distance_SGBM, disparity_SGBM, full_disparity_map, cropped_disparity_map, depth_map = results.values()\n",
    "\n",
    "    ###############################\n",
    "    ####### Chessboard Size #######\n",
    "    ###############################\n",
    "\n",
    "    #compute chessboard size using both distances\n",
    "    width_keypoints, height_keypoints = chessboard_size_estimation([cornersL, cornersR], distance_keypoints, f)\n",
    "    width_SGBM, height_SGBM = chessboard_size_estimation([cornersL, cornersR], distance_SGBM, f)\n",
    "\n",
    "    ###############################\n",
    "    ####### Chessboard Angle ######\n",
    "    ###############################\n",
    "\n",
    "    #estimate the angle between the chessboard and the camera’s image plane\n",
    "    angle_keypoints = chessboard_angle_estimation(disparity_columns, width_keypoints)\n",
    "\n",
    "    ###############################\n",
    "    ######## Visualization ########\n",
    "    ###############################\n",
    "    \n",
    "    #select visualization metrics\n",
    "    distance = distance_SGBM if method == 'SGBM' else distance_keypoints\n",
    "    chessboard_width, chessboard_height = ((width_SGBM, height_SGBM) if method == 'SGBM' else (width_keypoints, height_keypoints))\n",
    "\n",
    "    #display visual information\n",
    "    alarm_counter = display_information(\n",
    "        frameL,                    #frame where info is displayed\n",
    "        alarm_counter,             #alarm counter for flickering effect\n",
    "        distance,                  #distance to obstacle in mm\n",
    "        min_dist,                  #minimum safe distance in mm\n",
    "        chessboard_width,          #chessboard width in mm\n",
    "        chessboard_height,         #chessboard height in mm\n",
    "        angle_keypoints,           #angle of chessboard in degrees\n",
    "        chessboard_grid,           #chessboard grid size\n",
    "        cornersL,                  #refined corners of the left chessboard\n",
    "        foundL,                    #whether the chessboard was detected\n",
    "        frame_number,              #current frame number\n",
    "        video_length,              #total number of frames\n",
    "        output_video               #object for writing frames to output video\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    ####### Metrics Storage #######\n",
    "    ###############################\n",
    "\n",
    "    metrics_data[\"distances_keypoints\"].append(distance_keypoints)\n",
    "    metrics_data[\"distances_SGBM\"].append(distance_SGBM)\n",
    "    metrics_data[\"widths_keypoints\"].append(width_keypoints)\n",
    "    metrics_data[\"heights_keypoints\"].append(height_keypoints)\n",
    "    metrics_data[\"widths_SGBM\"].append(width_SGBM)\n",
    "    metrics_data[\"heights_SGBM\"].append(height_SGBM)\n",
    "    metrics_data[\"angles_keypoints\"].append(angle_keypoints)\n",
    "    metrics_data[\"disparity_maps\"].append(full_disparity_map)\n",
    "    metrics_data[\"depth_maps\"].append(depth_map)\n",
    "\n",
    "    #save the image for point cloud generation\n",
    "    if frame_number == 175: point_cloud_disp = full_disparity_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the loop, the algorithm releases the resources associated with the input video streams (left and right) as well as the output video file in order to free memory and avoid resource leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_video.release()\n",
    "right_video.release()\n",
    "output_video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, metrics function is invoked to compare distances, widths, and heights estimation using both methods across all processed frames and it generates and saves relevant plots for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Disparity Map map as /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/Disparity Map_map_frame87.png\n",
      "Saved Depth Map map as /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/Depth Map_map_frame87.png\n",
      "Saved Disparity Map map as /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/Disparity Map_map_frame174.png\n",
      "Saved Depth Map map as /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/Depth Map_map_frame174.png\n",
      "Saved Disparity Map map as /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/Disparity Map_map_frame260.png\n",
      "Saved Depth Map map as /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/Depth Map_map_frame260.png\n",
      "Distance comparison plot saved to /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/distance_comparison.png\n",
      "Chessboard width comparison plot saved to /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/width_comparison.png\n",
      "Chessboard height comparison plot saved to /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/height_comparison.png\n",
      "Relative distance difference plot saved to /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/relative_distance_difference.png\n",
      "Relative distance difference plot (log scale) saved to /home/andrea/Desktop/CV/[IPCV]_PernaAndrea/Project_Outcomes/relative_distance_difference_log.png\n"
     ]
    }
   ],
   "source": [
    "comparison_results = metrics(metrics_data, output_directory, min_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point cloud of a particular scene's frame is generated and saved in a PLY file for visualization is Sketchfab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved improved point cloud as robot_nav_pointcloud.ply\n"
     ]
    }
   ],
   "source": [
    "point_cloud = generate_point_cloud(point_cloud_disp, frameL, f, b, output_filename=\"robot_nav_pointcloud.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
